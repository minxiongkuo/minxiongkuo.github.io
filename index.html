<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Xiongkuo Min (闵雄阔)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="biography.html">Biography</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="publication.html">Publication</a></div>
<div class="menu-item"><a href="award.html">Award&nbsp;&amp;&nbsp;Honor</a></div>
<div class="menu-item"><a href="funding.html">Funding</a></div>
<div class="menu-item"><a href="patent.html">Patent</a></div>
<div class="menu-item"><a href="activity.html">Activity&nbsp;&amp;&nbsp;Service</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Xiongkuo Min (闵雄阔)</h1>
</div>
<table class="imgtable"><tr><td>
<img src="images/XiongkuoMin.jpg" alt="photo" width="150px" height="214px" />&nbsp;</td>
<td align="left"><p><b>Xiongkuo Min</b><br />
Associate Professor (tenure-track)<br />
Institute of Image Communication and Network Engineering<br />
Department of Electronic Engineering<br />
Shanghai Jiao Tong University, Shanghai, China<br />
minxiongkuo@sjtu.edu.cn<br />


<a href="https://www.researchgate.net/profile/Xiongkuo-Min-2">ResearchGate</a><br />
<a href="https://dblp.org/pid/139/6983.html">DBLP</a><br />
<a href="https://multimedia.sjtu.edu.cn/">SJTU Multimedia Lab</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I'm currently an Associate Professor (tenure-track) with the Institute of Image Communication and Network Engineering, Department of Electronic Engineering, Shanghai Jiao Tong University, where I joined in Oct. 2021.</p>
<p>I received my B.E. degree from Wuhan University, Wuhan, China, in 2013, and my Ph.D. degree from Shanghai Jiao Tong University, Shanghai, China, in 2018. From Jun. 2018 to Sept. 2021, I did my Postdoc at Shanghai Jiao Tong University. From Jan. 2016 to Jan. 2017, I was a visiting PhD student at University of Waterloo. From Jan. 2019 to Jan. 2021, I was a visiting scholar at The University of Texas at Austin and the University of Macau.</p>
<p>My research interests lie in the fields of multimedia, image/video processing, computer vision, and artificial intelligence, and particularly in:</p>
<ul>
<li><p>Image/video/audio quality assessment</p>
</li>
<li><p>Visual attention analysis and prediction</p>
</li>
<li><p>Visual enhancement and restoration</p>
</li>
<li><p>Multimodal information fusion</p>
</li>
<li><p>VR/AR/XR and metaverse</p>
</li>
<li><p>Virtual digital human</p>
</li>
<li><p>AI for healthcare</p>
</li>
</ul>
<div class="infoblock">
<div class="blockcontent">
<p>Looking for self-motivated students (Ph.D., master, and undergraduate students) working with me. For prospective students, please send me an email with your CV and transcript.
<br /> There is one master position available in Fall 2024. Please feel free to contact me if interested.</p>
</div></div>
<h2>News</h2>
<ul>
<li><p>07/2023, We receive the IEEE MSA-TC Best Paper Award - Honorable Mention.</p>
</li>
<li><p>06/2023, Undergraduate from our group wins the Best Bachelor Thesis Award of SJTU (Top 1%)</p>
</li>
<li><p>03/2023, Our survey paper wins the Hot Paper Award of SCIENCE CHINA Information Sciences</p>
</li>
<li><p>11/2022, We receive the First Prize of the Technological Invention Award of CSIG (中国图象图形学学会技术发明一等奖)</p>
</li>
<li><p>11/2022, We receive the Second Prize of the Teaching Achievement Award of CSIG (中国图象图形学学会教学成果二等奖)</p>
</li>
<li><p>10/2022, We receive the First Prize of the IEEE ICIP Grand Challenge on Video Surveillance Quality Assessment</p>
</li>
<li><p>09/2022, I'm sponsored by NSFC (general program)</p>
</li>
<li><p>09/2022, I'm sponsored by Shanghai Pujiang Talent Program</p>
</li>
<li><p>06/2022, We receive the Best Paper Award of IEEE BMSB</p>
</li>
<li><p>10/2021, I join Shanghai Jiao Tong University as a tenure-track Associate Professor</p>
</li>
<li><p>09/2021, I'm sponsored by NSFC (young scholar program)</p>
</li>
<li><p>07/2021, We receive the First Place Award of IEEE ICME Grand Challenge on Quality Assessment of Compressed UGC Videos</p>
</li>
<li><p>06/2021, We receive the Best Paper Runner-up Award of IEEE Transactions on Multimedia</p>
</li>
<li><p>02/2021, I received the Excellent Ph.D. Thesis Award of Chinese Institute of Electronics (CIE) (中国电子学会优博)</p>
</li>
<li><p>07/2019, We receive the Best Paper Award of IEEE International Workshop on Mobile Multimedia Computing (in conjunction with IEEE ICME)</p>
</li>
<li><p>12/2018, I'm sponsored by the Shanghai Super-Postdoc Incentive Plan</p>
</li>
<li><p>07/2018, We receive the Grand Prize of IEEE ICME Salient360! Grand Challenge</p>
</li>
<li><p>06/2018, I'm sponsored by the National Postdoctoral Program for Innovative Talents</p>
</li>
<li><p>06/2018, I pass my Ph.D. defense</p>
</li>
<li><p>07/2017, We receive the Special Award of IEEE ICME Salient360! Grand Challenge</p>
</li>
<li><p>07/2016, We receive the Best Student Paper Award of IEEE ICME<br /></p>
</li>
</ul>
<h2>Selected Publications</h2>
<p>More on <a href="publication.html">Publication</a> page.<br /></p>
<ul>
<li><p><b>Screen Content Quality Assessment: Overview, Benchmark, and Beyond</b><br />
Xiongkuo Min, Ke Gu, Guangtao Zhai, Xiaokang Yang, Wenjun Zhang, Patrick Le Callet, and Chang Wen Chen<br />
<i>ACM Computing Surveys (CSUR)</i>, vol. 54, no. 9, pp. 1-36, 2022.
<br /><font color=red size=+0.00>ESI Highly Cited Paper</font></p>
</li>
</ul>
<ul>
<li><p><b>Study of Subjective and Objective Quality Assessment of Audio-Visual Signals</b><br />
Xiongkuo Min, Guangtao Zhai, Jiantao Zhou, Mylene C.Q. Farias, and Alan Conrad Bovik<br />
<i>IEEE Transactions on Image Processing (TIP)</i>, vol. 29, pp. 6054–6068, 2020.<br />
[<a href="https://github.com/utlive/avqa">Code</a>]
[<a href="https://live.ece.utexas.edu/research/avqa/index.html">LIVE-SJTU A/V-QA Database</a>]</p>
</li>
</ul>
<ul>
<li><p><b>A Multimodal Saliency Model for Videos With High Audio-Visual Correspondence</b><br />
Xiongkuo Min, Guangtao Zhai, Jiantao Zhou, Xiao-Ping Zhang, Xiaokang Yang, and Xinping Guan<br />
<i>IEEE Transactions on Image Processing (TIP)</i>, vol. 29, pp. 3805-3819, 2020.<br />
[<a href="https://mega.nz/file/xVsDTKQQ#KoWypaLYk2D5Q7xuAt_du5j4v_osfLNjGdbPWfZ427c">Code</a>]
[<a href="https://mega.nz/file/IAcRhSJZ#PKqkGbO96C1zxbEFj1WgJ5WOdnnQzxLionjV0SV-5Xw">AVA Database</a>]</p>
</li>
</ul>
<ul>
<li><p><b>Perceptual Image Quality Assessment: A Survey</b><br />
Guangtao Zhai, and Xiongkuo Min<br />
<i>SCIENCE CHINA Information Sciences</i>, vol. 63, no. 11, pp. 211301, 2020.
<br /><font color=red size=+0.00>Hot Paper Award</font>, <font color=red size=+0.00>ESI Highly Cited Paper</font></p>
</li>
</ul>
<ul>
<li><p><b>Blind Quality Assessment Based on Pseudo Reference Image</b><br />
Xiongkuo Min, Ke Gu, Guangtao Zhai, Jing Liu, Xiaokang Yang, and Chang Wen Chen<br />
<i>IEEE Transactions on Multimedia (TMM)</i>, vol. 20, no. 20, pp. 2049-2062, 2018.<br />
[<a href="https://drive.google.com/open?id=1hox6cXcuE3vr1iIsvZkgOgtLLTLE1Nnb">Code: BPRI</a>]
<br /><font color=red size=+0.00>Best Paper Runner-up Award</font>, <font color=red size=+0.00>ESI Highly Cited Paper</font></p>
</li>
</ul>
<ul>
<li><p><b>Blind Image Quality Estimation via Distortion Aggravation</b><br />
Xiongkuo Min, Guangtao Zhai, Ke Gu, Yutao Liu, and Xiaokang Yang<br />
<i>IEEE Transactions on Broadcasting (TBC)</i>, vol. 64, no. 2, pp. 508-517, 2018.<br />
[<a href="https://drive.google.com/open?id=1C_NxTLvnBOJDGhqqtixCkra0LIMP6loF">Code: BMPRI</a>]</p>
</li>
</ul>
<ul>
<li><p><b>Unified Blind Quality Assessment of Compressed Natural, Graphic, and Screen Content Images</b><br />
Xiongkuo Min, Kede Ma, Ke Gu, Guangtao Zhai, Zhou Wang, and Weisi Lin<br />
<i>IEEE Transactions on Image Processing (TIP)</i>, vol. 26, no. 11, pp. 5462-5474, 2017.<br />
[<a href="https://sites.google.com/site/minxiongkuo/uca?authuser=0">Project</a>]
[<a href="https://drive.google.com/open?id=0BzIV-pviJ97tQTJ1QzR6U3VJTFE">Code: UCA</a>]
[<a href="https://mega.nz/file/xUtWAZLb#YIpqVOs3swZE6fxK5iupIQeA1hBwAVoZE40_hDttrV4">Database: CCT</a>]
<br /><font color=red size=+0.00>ESI Hot Paper</font></p>
</li>
</ul>
<h2>Featured Research</h2>
<table class="imgtable"><tr><td>
<img src="images/Survey.png" alt="photo" width="300px" height="180px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Surveys for Perceptual Quality Assessment</b></font></b></p>
<p><p style="margin-top: -0.5em"></p></p>
<p>- <b>[SCIS]</b> Perceptual Image Quality Assessment: A Survey<br />
G. Zhai, and X. Min, <i>SCIENCE CHINA Information Sciences</i>, vol. 63, no. 11, pp. 211301, 2020.
<br /><font color=red size=+0.00>Hot Paper Award</font>, <font color=red size=+0.00>ESI Highly Cited Paper</font></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM CSUR]</b> Screen Content Quality Assessment: Overview, Benchmark, and Beyond<br />
X. Min, K. Gu, G. Zhai, X. Yang, W. Zhang, P. L. Callet, and C. W. Chen, <i>ACM Computing Surveys</i>, vol. 54, no. 9, pp. 1-36, 2022.
<br /><font color=red size=+0.00>ESI Highly Cited Paper</font></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/AIGC.png" alt="photo" width="300px" height="180px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>AIGC Image Quality Assessment</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TCSVT]</b> AGIQA-3K: An Open Database for AI-Generated Image Quality Assessment<br />
C. Li, Z. Zhang, H. Wu, W. Sun, X. Min, X. Liu, G. Zhai, and W. Lin, <i>IEEE TCSVT</i>, 2023. [<a href="https://github.com/lcysyzxdxc/AGIQA-3k-Database">Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[CICAI]</b> AIGCIQA2023: A Large-scale Image Quality Assessment Database for AI Generated Images: From the Perspectives of Quality, Authenticity and Correspondence<br />
J. Wang, H. Duan, J. Liu, S. Chen, X. Min, and G. Zhai, <i>CICAI</i>, 2023. [<a href="https://www.terabox.com/sharing/link?surl=DtV-A9XiuQQDvVPXn6rYvg">Database</a>]</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/Point.png" alt="photo" width="300px" height="130px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Point Cloud, Mesh Quality Assessment</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IJCAI]</b> MM-PCQA: Multi-Modal Learning for No-reference Point Cloud Quality Assessment<br />
Z. Zhang, W. Sun, X. Min, Q. Zhou, J. He, Q. Wang, and G. Zhai, <i>IJCAI</i>, 2023. [<a href="https://github.com/zzc-1998/MM-PCQA">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TCSVT]</b> No-Reference Quality Assessment for 3D Colored Point Cloud and Mesh Models<br />
Z. Zhang, W. Sun, X. Min, T. Wang, W. Lu, and G. Zhai, <i>IEEE TCSVT</i>, vol. 32, no. 11, pp. 7618-7631, 2022. [<a href="https://github.com/zzc-1998/NR-3DQA">Code</a>]</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/Enhancement.png" alt="photo" width="300px" height="180px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Image/Video Enhancement/Restoration/Interpolation etc.</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE CVPR]</b> Blurry Video Frame Interpolation<br />
W. Shen, W. Bao, G. Zhai, L. Chen, X. Min, and Z. Gao, <i>IEEE/CVF CVPR</i>, 2020, pp. 5114-5123. [<a href="https://github.com/laomao0/BIN/tree/master">Project &amp; Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> Video Frame Interpolation and Enhancement via Pyramid Recurrent Framework<br />
W. Shen, W. Bao, G. Zhai, L. Chen, X. Min, and Z. Gao, <i>IEEE TIP</i>, vol. 30, pp. 277-292, 2021. [<a href="https://github.com/laomao0/BIN/tree/master">Project & Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> Self-Conditioned Probabilistic Learning of Video Rescaling<br />
Y. Tian, G. Lu, X. Min, Z. Che, G. Zhai, G. Guo, and Z. Gao, <i>IEEE/CVF ICCV</i>, 2021, pp. 4490-4499. [<a href="https://github.com/tianyuan168326/SelfC">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TMM]</b> Develop then Rival: A Human Vision-Inspired Framework for Superimposed Image Decomposition<br />
H. Duan, W. Shen, X. Min, Y. Tian, J.-H. Jung, X. Yang, and G. Zhai, <i>IEEE TMM</i>, 2022.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TGRS]</b> Implicit Neural Representation Learning for Hyperspectral Image Super-Resolution<br />
K. Zhang, D. Zhu, X. Min, and G. Zhai, <i>IEEE TGRS</i>, vol. 61, pp. 1-12, 2022.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TMC]</b> Dynamic Backlight Scaling Considering Ambient Luminance for Mobile Videos on LCD Displays<br />
W. Sun, X. Min, G. Zhai, K. Gu, S. Ma, and X. Yang, <i>IEEE TMC</i>, vol. 21, no. 1, pp. 110-124, 2022. [<a href="https://github.com/sunwei925/DBSVideoDatabase">Database</a>]</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/UGC.png" alt="photo" width="300px" height="250px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Image Quality Assessment in-the-Wild</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE JSTSP]</b> Blind Quality Assessment for in-the-Wild Images via Hierarchical Feature Fusion and Iterative Mixed Database Training<br />
W. Sun, X. Min, D. Tu, S. Ma, and G. Zhai, <i>IEEE JSTSP</i>, 2023. [<a href="https://github.com/sunwei925/StairIQA">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TMM]</b> Blind Image Quality Assessment Via Cross-View Consistency<br />
Y. Zhu, Y. Li, W. Sun, X. Min, G. Zhai, and X. Yang, <i>IEEE TMM</i>, vol. 25, pp. 7364-7377, 2022.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TCSVT]</b> Synergetic Assessment of Quality and Aesthetic: Approach and Comprehensive Benchmark Dataset<br />
K. Zhang, D. Zhu, X. Min, Z. Gao, and G. Zhai, <i>IEEE TCSVT</i>, 2023.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[NeurIPS]</b> Perceptual Attacks of No-Reference Image Quality Models with Human-in-the-Loop<br />
W. Zhang, D. Li, X. Min, G. Zhai, G. Guo, X. Yang, and K. Ma, <i>NeurIPS</i>, 2022, vol. 35, pp. 2916-2929. [<a href="https://github.com/zwx8981/PerceptualAttack_BIQA">Code</a>]</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/UGCvideo.png" alt="photo" width="300px" height="150px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Video Quality Assessment in-the-Wild</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM MM]</b> A Deep Learning based No-reference Quality Assessment Model for UGC Videos<br />
W. Sun, X. Min, W. Lu, and G. Zhai, <i>ACM MM</i>, 2022, pp. 856-865. [<a href="https://github.com/sunwei925/SimpleVQA">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE CVPR]</b> MD-VQA: Multi-Dimensional Quality Assessment for UGC Live Videos<br />
Z. Zhang, W. Wu, W. Sun, D. Tu, W. Lu, X. Min, Y. Chen, and G. Zhai, <i>IEEE/CVF CVPR</i>, 2023, 1746-1755. [<a href="https://github.com/zzc-1998/MD-VQA">Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE ICMEW]</b> Deep Learning Based Full-Reference and No-Reference Quality Assessment Models for Compressed UGC Videos<br />
W. Sun, T. Wang, X. Min, F. Yi, and G. Zhai, <i>IEEE ICMEW</i>, 2021, pp. 1-6. [<a href="https://github.com/sunwei925/CompressedVQA">Code</a>]
<br /><font color=red size=+0.00>First Place Award of IEEE ICME 2021 Grand Challenge on Quality Assessment of Compressed UGC Videos</font></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/OSD.png" alt="photo" width="300px" height="150px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Blind IQA with Opinion Score Distributions</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM MM]</b> Image Quality Assessment: From Mean Opinion Score to Opinion Score Distribution<br />
Y. Gao, X. Min, Y. Zhu, J. Li, X.-P. Zhang, and G. Zhai, <i>ACM MM</i>, 2022, pp. 997–1005. [<a href="https://github.com/YixuanGao98/Image-Quality-Assessment-From-Mean-Opinion-Score-to-Opinion-Score-Distribution">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TCSVT]</b> Blind Image Quality Assessment: A Fuzzy Neural Network for Opinion Score Distribution Prediction<br />
Y. Gao, X. Min, Y. Zhu, X.-P. Zhang, and G. Zhai, <i>IEEE TCSVT</i>, 2023. [<a href="https://github.com/YixuanGao98/Image-Quality-Assessment-From-Mean-Opinion-Score-to-Opinion-Score-Distribution">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TCSVT]</b> Image Quality Score Distribution Prediction via Alpha Stable Model<br />
Y. Gao, X. Min, W. Zhu, X.-P. Zhang, and G. Zhai, <i>IEEE TCSVT</i>, vol. 33, no. 6, pp. 2656-2671, 2023. [<a href="https://github.com/YixuanGao98/Image-Quality-Score-Distribution-Prediction-via-Alpha-Stable-Model">Database &amp; Code</a>]</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/Gaze.png" alt="photo" width="300px" height="180px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Human Gaze and Human-Object Interaction Detection</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE CVPR]</b> End-to-End Human-Gaze-Target Detection with Transformers<br />
D. Tu, X. Min, H. Duan, G. Guo, G. Zhai, and W. Shen, <i>IEEE/CVF CVPR</i>, 2022, pp. 2192-2200.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TCSVT]</b> Un-Gaze: A Unified Transformer for Joint Gaze-Location and Gaze-Object Detection<br />
D. Tu, W. Shen, W. Sun, X. Min, G. Zhai, and C. W. Chen, <i>IEEE TCSVT</i>, 2023.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[NeurIPS]</b> Video-based Human-Object Interaction Detection from Tubelet Tokens<br />
D. Tu, W. Sun, X. Min, G. Zhai, and W. Shen, <i>NeurIPS</i>, 2022, vol. 35, pp. 23345-23357.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ECCV]</b> Iwin: Human-Object Interaction Detection via Transformer with Irregular Windows<br />
D. Tu, X. Min, H. Duan, G. Guo, G. Zhai, and W. Shen, <i>ECCV</i>, 2022, pp. 87-103.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/Hiding.png" alt="photo" width="300px" height="150px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Information Hiding</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE CVPR]</b> Learning Invisible Markers for Hidden Codes in Offline-to-online Photography<br />
J. Jia, Z. Gao, D. Zhu, X. Min, G. Guo, and G. Zhai, <i>IEEE/CVF CVPR</i>, 2022, pp. 2273-2282.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TCYB]</b> RIHOOP: Robust Invisible Hyperlinks in Offline and Online Photographs<br />
J. Jia, Z. Gao, K. Chen, M. Hu, X. Min, G. Zhai, and X. Yang, <i>IEEE TCYB</i>, vol. 52, no. 7, pp. 7094-7106, 2022.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TMM]</b> RIVIE: Robust Inherent Video Information Embedding<br />
J. Jia, Z. Gao, D. Zhu, X. Min, M. Hu, and G. Zhai, <i>IEEE TMM</i>, vol. 25, pp. 7607-7620, 2023.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/Specific.png" alt="photo" width="300px" height="280px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Quality Assessment for Specific Applications</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> A Metric for Light Field Reconstruction, Compression, and Display Quality Evaluation<br />
X. Min, J. Zhou, G. Zhai, P. L. Callet, X. Yang, and X. Guan, <i>IEEE TIP</i>, vol. 29, pp. 3790-3804, 2020. [<a href="https://mega.nz/file/BQdXWJxA#kEtN1IMesXoSC3bdTMzsC6E2cCP7Puu9j3a47nxQbUw">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TMI]</b> Blind Image Quality Assessment for Pathological Microscopic Image under Screen and Immersion Scenarios<br />
Y. Guo, M. Hu, X. Min, Y. Wang, M. Dai, G. Zhai, X.-P. Zhang, and X. Yang, <i>IEEE TMI</i>, 2023. [<a href="https://github.com/mikugyf/PMIQD-SIS">Database &amp; Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TBC]</b> Deep Neural Network for Blind Visual Quality Assessment of 4K Content<br />
W. Lu, W. Sun, X. Min, W. Zhu, Q. Zhou, J. He, Q. Wang, Z. Zhang, T. Wang, and G. Zhai, <i>IEEE TBC</i>, vol. 69, no. 2, pp. 406-421, 2023.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE ToG]</b> A Deep Learning Based Multi-Dimensional Aesthetic Quality Assessment Method for Mobile Game Images<br />
T. Wang, W. Sun, W. Wu, Y. Chen, X. Min, W. Lu, Z. Zhang, and G. Zhai, <i>IEEE ToG</i>, 2022.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TBC]</b> A Wavelet-Predominant Algorithm Can Evaluate Quality of THz Security Image and Identify Its Usability<br />
M. Hu, G. Zhai, R. Xie, X. Min, Q. Li, and X. Yang, <i>IEEE TBC</i>, vol. 66, no. 1, pp. 140-152, 2020. [<a href="https://doi.org/10.6084/m9.figshare.7700123.v3">Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE ICIP]</b> Surveillance Video Quality Assessment Based on Quality Related Retraining<br />
Z. Zhang, W. Lu, W. Sun, X. Min, T. Wang, and G. Zhai, <i>IEEE ICIP</i>, 2022, pp. 4278-4282.
<br /><font color=red size=+0.00>The First Prize of the IEEE ICIP Grand Challenge - Video Distortion Detection and Classification in the Context of Video Surveillance</font></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/VRsaliency.png" alt="photo" width="300px" height="250px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Visual Attention Prediction in Virtual Reality </b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM TOMM]</b> Learning a Deep Agent to Predict Head Movement in 360-Degree Images<br />
Y. Zhu, G. Zhai, X. Min, and J. Zhou, <i>ACM TOMM</i>, vol. 16, no. 4, pp. 130:1-130:23, 2020.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TMM]</b> The Prediction of Saliency Map for Head and Eye Movements in 360 Degree Images<br />
Y. Zhu, G. Zhai, X. Min, and J. Zhou, <i>IEEE TMM</i>, vol. 22, no. 9, pp. 2331-2344, 2020.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[SPIC]</b> The Prediction of Head and Eye Movement for 360 Degree Images<br />
Y. Zhu, G. Zhai, and X. Min, <i>SPIC</i>, vol. 69, pp. 15-25, 2018.
<br /><font color=red size=+0.00>Special Award of IEEE ICME 2017 Salient360! Grand Challenge</font></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TCSVT]</b> Viewing Behavior Supported Visual Saliency Predictor for 360 Degree Videos<br />
Y. Zhu, G. Zhai, Y. Yang, H. Duan, X. Min, and X. Yang, <i>IEEE TCSVT</i>, vol. 32, no. 7, pp. 4188-4201, 2022.
<br /><font color=red size=+0.00>Grand Prize of IEEE ICME 2018 Salient360! Grand Challenge</font></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TMM]</b> Unified Audio-visual Saliency Model for Omnidirectional Videos with Spatial Audio<br />
D. Zhu, K. Zhang, N. Zhang, Q. Zhou, X. Min, G. Zhai, and X. Yang, <i>IEEE TMM</i>, 2023.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/VRquality.png" alt="photo" width="300px" height="200px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Quality Assessment and Transmission in Virtual Reality </b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE JSTSP]</b> MC360IQA: The Multi-Channel CNN for Blind 360-Degree Image Quality Assessment<br />
W. Sun, X. Min, G. Zhai, K. Gu, H. Duan, and S. Ma, <i>IEEE JSTSP</i>, vol. 14, no. 1, pp. 64-77, 2020. [<a href="https://github.com/sunwei925/MC360IQA">Code</a>]
[<a href="https://github.com/sunwei925/CVIQDatabase">Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE ISCAS]</b> Perceptual Quality Assessment of Omnidirectional Images<br />
H. Duan, G. Zhai, X. Min, Y. Zhu, Y. Fang, X. Yang, <i>IEEE ISCAS</i>, 2018, pp. 1-5. [<a href="https://mega.nz/#!FqxxRQRR!4Ju2qcmmo6Ced_7nRBXXqAaDcjqxjH2uUFnXIeyE2ts">Database</a>]</p>
<p><p style="margin-top: -0.5em"></p></p>
<p>- <b>[IEEE JSTSP]</b> Attentive Deep Image Quality Assessment for Omnidirectional Stitching<br />
H. Duan, X. Min, W. Sun, Y. Zhu, X.-P. Zhang, and G. Zhai, <i>IEEE JSTSP</i>, 2023. [<a href="https://terabox.com/s/1JRCULEOKirsF5cJZ6vRrcQ">Database(TeraBox)</a>]
[<a href="https://pan.baidu.com/s/1AbiHSFK0fM2ebzdb2zjEBw?pwd=d07i">Database(BaiduCloud)</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TWC]</b> QoE Driven VR 360° Video Massive MIMO Transmission<br />
L. Teng, G. Zhai, Y. Wu, X. Min, W. Zhang, Z. Ding, and C. Xiao, <i>IEEE TWC</i>, vol. 21, no. 1, pp. 18-33, 2022.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/AR.png" alt="photo" width="300px" height="160px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Attention and Experience Prediction in Augmented Reality </b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM MM]</b> Saliency in Augmented Reality<br />
H. Duan, W. Shen, X. Min, D. Tu, J. Li, and G. Zhai, <i>ACM MM</i>, 2022, pp. 6549-6558. [<a href="https://github.com/DuanHuiyu/ARSaliency">Code &amp; Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM TOMM]</b> Toward Visual Behavior and Attention Understanding for Augmented 360 Degree Videos<br />
Y. Zhu, X. Min, D. Zhu, G. Zhai, X. Yang, W. Zhang, K. Gu, and J. Zhou, <i>ACM TOMM</i>, vol. 19, no. 2s, pp. 99:1-99:24, 2023.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> Confusing Image Quality Assessment: Toward Better Augmented Reality Experience<br />
H. Duan, X. Min, Y. Zhu, G. Zhai, X. Yang, and P. L. Callet, <i>IEEE TIP</i>, vol. 31, pp. 7206-7221, 2022. [<a href="https://github.com/DuanHuiyu/ARIQA">Code &amp; Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE BMSB]</b> Augmented Reality Image Quality Assessment Based on Visual Confusion Theory<br />
H. Duan, L. Guo, W. Sun, X. Min, L. Chen, and G. Zhai, <i>IEEE BMSB</i>, 2022, pp. 1-6. [<a href="https://github.com/DuanHuiyu/ARIQA">Code &amp; Database</a>]
<br /><font color=red size=+0.00>Best Paper Award</font></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/AVQA.png" alt="photo" width="300px" height="180px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Audio-Visual Quality Assessment</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> Study of Subjective and Objective Quality Assessment of Audio-Visual Signals<br />
X. Min, G. Zhai, J. Zhou, M. C.Q. Farias, and A. C. Bovik, <i>IEEE TIP</i>, vol. 29, pp. 6054–6068, 2020. [<a href="https://github.com/utlive/avqa">Code</a>]
[<a href="https://live.ece.utexas.edu/research/avqa/index.html">LIVE-SJTU A/V-QA Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> Attention-Guided Neural Networks for Full-Reference and No-Reference Audio-Visual Quality Assessment<br />
Y. Cao, X. Min, W. Sun, and G. Zhai, <i>IEEE TIP</i>, vol. 32, pp. 1882-1896, 2023. [<a href="https://github.com/charlotte9524/ANNAVQA-pytorch">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> Subjective and Objective Audio-Visual Quality Assessment for User Generated Content<br />
Y. Cao, X. Min, W. Sun, and G. Zhai, <i>IEEE TIP</i>, 2023.</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/Dehaze.png" alt="photo" width="300px" height="280px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Quality Assessment for Enhancement (Haze, Light, Stability, etc.)</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TMM]</b> Quality Evaluation of Image Dehazing Methods Using Synthetic Hazy Images<br />
X. Min, G. Zhai, K. Gu, Y. Zhu, J.o Zhou, G. Guo, X. Yang, X. Guan, and W. Zhang, <i>IEEE TMM</i>, vol. 21, no. 9, pp. 2319-2333, 2019. [<a href="https://drive.google.com/open?id=1zArIS33JhhPq-ZHPBwcKytpMuG0Bnn6C">Code: DEHAZEfr</a>]
[<a href="https://mega.nz/file/NMFACRgb#nkabpFrlAjUPqhBF1G1dPDFI4IGc6D11GA9IBY-1oRU">Database: SHRQ</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TITS]</b> Objective Quality Evaluation of Dehazed Images<br />
X. Min, G. Zhai, K. Gu, X. Yang, and X. Guan, <i>IEEE TITS</i>, vol. 20, no. 9, pp. 2879-2892, 2019. [<a href="https://drive.google.com/open?id=1Kw1t1gXseQTlSeZr-tWzcIYKBIP1f97t">Code: DHQI</a>]
[<a href="https://mega.nz/file/5JUzVZiQ#S26bMMoQA1MsLCmjnconetcSPXI9Dde3GStm4hh1xDk">Database: DHQ</a>]
[<a href="https://mega.nz/file/lc8hmb7I#mqhR6pTX0EA6YY6ba9CPDPdHIRcxpdT6bhyYaaSUdtY">Database: rDHAZY</a>]
[<a href="https://mega.nz/file/QdF1RTjI#zOwuk1GgWVHWH7hkZNieNyEkC_gl8qMCw4RSHtChet4">Database: rFRIDA</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TITS]</b> HazDesNet: An End-to-End Network for Haze Density Prediction<br />
J. Zhang, X. Min, Y. Zhu, G. Zhai, J. Zhou, X. Yang, and W. Zhang, <i>IEEE TITS</i>, vol. 23, no. 4, pp. 3087-3102, 2020. [<a href="https://github.com/JiaheZhang/HazDesNet">Code & Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM TOMM]</b> Perceptual Quality Assessment of Low-light Image Enhancement<br />
G. Zhai, W. Sun, X. Min, and J. Zhou, <i>ACM TOMM</i>, vol. 17, no. 4, pp. 130:1-130:24, 2021. [<a href="https://github.com/sunwei925/LIEQAIndex">Code: LIEQA</a>] [<a href="https://github.com/sunwei925/LIEQDatabase">Database: LIEQ</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM MM]</b> StableVQA: A Deep No-Reference Quality Assessment Model for Video Stability<br />
T. Kou, X. Liu, W. Sun, J. Jia, X. Min, G. Zhai, and N. Liu, <i>ACM MM</i>, 2023. [<a href="https://github.com/qmme/stablevqa">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE CVPRW]</b> VDPVE: VQA Dataset for Perceptual Video Enhancement<br />
Y. Gao, Y. Cao, T. Kou, W. Sun, Y. Dong, X. Liu, X. Min, and G. Zhai, <i>IEEE/CVF CVPRW</i>, 2023, pp. 1474-1483. [<a href="https://codalab.lisn.upsaclay.fr/competitions/10252">Challenge</a>]
[<a href="https://github.com/YixuanGao98/VDPVE">Database</a>]</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/Screen.png" alt="photo" width="300px" height="250px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Screen Content Quality Assessment</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM CSUR]</b> Screen Content Quality Assessment: Overview, Benchmark, and Beyond<br />
X. Min, K. Gu, G. Zhai, X. Yang, W. Zhang, P. L. Callet, and C. W. Chen, <i>ACM Computing Surveys</i>, vol. 54, no. 9, pp. 1-36, 2022.
<br /><font color=red size=+0.00>ESI Highly Cited Paper</font></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> Unified Blind Quality Assessment of Compressed Natural, Graphic, and Screen Content Images<br />
X. Min, K. Ma, K. Gu, G. Zhai, Z. Wang, and W. Lin, <i>IEEE TIP</i>, vol. 26, no. 11, pp. 5462-5474, 2017. [<a href="https://sites.google.com/site/minxiongkuo/uca?authuser=0">Project</a>]
[<a href="https://drive.google.com/open?id=0BzIV-pviJ97tQTJ1QzR6U3VJTFE">Code: UCA</a>]
[<a href="https://mega.nz/file/xUtWAZLb#YIpqVOs3swZE6fxK5iupIQeA1hBwAVoZE40_hDttrV4">Database: CCT</a>]
<br /><font color=red size=+0.00>ESI Hot Paper</font></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TBC]</b> Subjective and Objective Quality Assessment of Compressed Screen Content Videos<br />
T. Li, X. Min, H. Zhao, G. Zhai, Y. Xu, and W. Zhang, <i>IEEE TBC</i>, vol. 67, no. 2, pp. 438-449, 2021. [<a href="https://mega.nz/folder/kE0A0LjZ#XJhN5IX7SYl-1_0n4oTa3Q">Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TVCG]</b> Evaluating Quality of Screen Content Images Via Structural Variation Analysis<br />
K. Gu, J. Qiao, X. Min, G. Yue, W. Lin, and D. Thalmann, <i>IEEE TVCG</i>, vol. 24, no. 10, pp. 2689-2701, 2018. [<a href="https://kegu.netlify.app/CODE/CODE_2018TVCG.rar">Code</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIE]</b> A Fast Reliable Image Quality Predictor by Fusing Micro- and Macro-Structures<br />
K. Gu, L. Li, H. Lu, X. Min, and W. Lin, <i>IEEE TIE</i>, vol. 64, no. 5, pp. 3903-3912, 2017. [<a href="https://kegu.netlify.app/CODE/CODE_2017TIE.rar">Code</a>]
<br /><font color=red size=+0.00>ESI Highly Cited Paper</font></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[SP]</b> Saliency-Induced Reduced-Reference Quality Index for Natural Scene and Screen Content Images<br />
X. Min, K. Gu, G. Zhai, M. Hu, and X. Yang, <i>SP</i>, vol. 145, pp. 127-136, 2018. [<a href="https://drive.google.com/open?id=1Kzrq3tBAQJF-lPDLaO7a2-noS86eDYuo">Code</a>]</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/MMS.png" alt="photo" width="300px" height="250px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>Multimodal (Audio, Visual, Text, etc.) Saliency Prediction</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> A Multimodal Saliency Model for Videos With High Audio-Visual Correspondence<br />
X. Min, G. Zhai, J. Zhou, X.-P. Zhang, X. Yang, and X. Guan, <i>IEEE TIP</i>, vol. 29, pp. 3805-3819, 2020. [<a href="https://mega.nz/file/xVsDTKQQ#KoWypaLYk2D5Q7xuAt_du5j4v_osfLNjGdbPWfZ427c">Code</a>]
[<a href="https://mega.nz/file/IAcRhSJZ#PKqkGbO96C1zxbEFj1WgJ5WOdnnQzxLionjV0SV-5Xw">AVA Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM TOMM]</b> Fixation Prediction through Multimodal Analysis<br />
X. Min, G. Zhai, K. Gu, and X. Yang, <i>ACM TOMM</i>, vol. 13, no. 1, pp. 6:1-6:23, 2017. [<a href="https://mega.nz/file/9NM2iBSA#57cIhULAjLOX5ygYJcmVOaVejoN5tl55Nb_v04rpc6Y">Code</a>]
[<a href="https://mega.nz/file/IAcRhSJZ#PKqkGbO96C1zxbEFj1WgJ5WOdnnQzxLionjV0SV-5Xw">Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TIP]</b> How is Gaze Influenced by Image Transformations? Dataset and Model<br />
Z. Che, A. Borji, G. Zhai, X. Min, G. Guo, and P. L. Callet, <i>IEEE TIP</i>, vol. 29, pp. 2287-2300, 2020. [<a href="https://github.com/CZHQuality/Sal-CFS-GAN">Code</a>]
[<a href="https://ieee-dataport.org/documents/transformed-saliency-dataset">Database</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[ACM TOMM]</b> A Novel Lightweight Audio-visual Saliency Model for Videos<br />
D. Zhu, X. Shao, Q. Zhou, X. Min, G. Zhai, and X. Yang, <i>ACM TOMM</i>, vol. 19, no. 4, pp. 147:1-147:22, 2023.</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE ISCAS]</b> The Influence of Text-guidance on Visual Attention<br />
Y. Sun, X. Min, H. Duan, and G. Zhai, IEEE ISCAS/, 2023, pp.1-5.
<br /><font color=red size=+0.00>IEEE MSA-TC Best Paper Award - Honorable Mention</font></p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/PRI.png" alt="photo" width="300px" height="156px" />&nbsp;</td>
<td align="left"><p><b><font color=black size=+1><b>BIQA Based on Pseudo References</b></font></b></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TMM]</b> Blind Quality Assessment Based on Pseudo Reference Image<br />
X. Min, K. Gu, G. Zhai, J. Liu, X. Yang, and C. W. Chen, <i>IEEE TMM</i>, vol. 20, no. 20, pp. 2049-2062, 2018. [<a href="https://drive.google.com/open?id=1hox6cXcuE3vr1iIsvZkgOgtLLTLE1Nnb">Code: BPRI</a>]
<br /><font color=red size=+0.00>Best Paper Runner-up Award</font>, <font color=red size=+0.00>ESI Highly Cited Paper</font></p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE TBC]</b> Blind Image Quality Estimation via Distortion Aggravation<br />
X. Min, G. Zhai, K. Gu, Y. Liu, and X. Yang, <i>IEEE TBC</i>, vol. 64, no. 2, pp. 508-517, 2018. [<a href="https://drive.google.com/open?id=1C_NxTLvnBOJDGhqqtixCkra0LIMP6loF">Code: BMPRI</a>]</p>
<p><p style="margin-top: -0.5em"></p>
- <b>[IEEE ICME]</b> Blind Quality Assessment of Compressed Images via Pseudo Structural Similarity<br />
X. Min, G. Zhai, K. Gu, Y. Fang, X. Yang, X. Wu, J. Zhou, and X. Liu, <i>IEEE ICME</i>, 2016, pp. 1-6. [<a href="https://drive.google.com/open?id=0BzIV-pviJ97tUnVoVFlpS1VRWFk">Code</a>]
<br /><font color=red size=+0.00>Best Student Paper Award</font></p>
</td></tr></table>
<h2>Contact</h2>
<p>Office: #5-100 SEIEE Building, Shanghai Jiao Tong University<br />
Mail: #5-100 SEIEE Building, 800 Dong Chuan Rd, Shanghai 200240, China<br />
Web: XXXXXX<br />
Email: minxiongkuo@sjtu.edu.cn OR minxiongkuo@gmail.com<br /></p>
<div id="footer">
<div id="footer-text">
Page generated 2023-11-10 15:38:46 CST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
